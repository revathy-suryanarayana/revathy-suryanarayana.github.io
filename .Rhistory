render_site()
rmarkdown::render_site()
q()
install.packages("rmarkdown")
install.packages("distill")
library(pretrends)
library(pretrends)
library(readxl)
beta_input <- read_excel("C:/Users/revat/Dropbox/beta.xlsx")
beta <- as.matrix(beta_input$beta)
t_vec = as.matrix(beta_input$t)
results <- read_excel("C:/Users/revat/Dropbox/results.xlsx")
sigma = as.matrix(results)
referencePeriod <- -1 #This is the omitted period in the regression
slope50 <-
slope_for_power(sigma = sigma,
targetPower = 0.5,
tVec = t_vec,
referencePeriod = referencePeriod)
slope50
library(pretrends)
library(pretrends)
library(readxl)
beta_input <- read_excel("C:/Users/revat/Dropbox/beta.xlsx")
beta <- as.matrix(beta_input$beta)
t_vec = as.matrix(beta_input$t)
results <- read_excel("C:/Users/revat/Dropbox/results.xlsx")
sigma = as.matrix(results)
referencePeriod <- -1 #This is the omitted period in the regression
slope50 <-
slope_for_power(sigma = sigma,
targetPower = 0.5,
tVec = t_vec,
referencePeriod = referencePeriod)
slope50
pretrendsResults <-
pretrends(betahat = beta,
sigma = sigma,
tVec = t_vec,
referencePeriod = referencePeriod,
deltatrue = slope50 * (t_vec - referencePeriod))
pretrendsResults$event_plot
pretrendsResults$df_power
pretrendsResults$df_eventplot
pretrendsResults$event_plot_pretest
install.packages(distill)
install.packages("distill")
devtools::install_github("synth-inference/synthdid")
install.packages(devtools)
install.packages("devtools"")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
devtools::install_github("synth-inference/synthdid")
install.packages(c("blob", "bookdown", "broom", "bslib", "cachem", "car", "classInt", "cli", "colorspace", "curl", "data.table", "dbplyr", "digest", "dplyr", "DRDID", "dtplyr", "e1071", "evaluate", "fansi", "fastmap", "forcats", "fs", "gargle", "ggplot2", "ggpubr", "ggrepel", "ggsci", "googledrive", "googlesheets4", "gtable", "haven", "highr", "hms", "htmltools", "httr", "isoband", "jpeg", "jsonlite", "knitr", "lme4", "lubridate", "markdown", "modelr", "openssl", "pbapply", "pbkrtest", "pillar", "png", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "readr", "readxl", "rgeos", "rlang", "rmarkdown", "rnaturalearth", "rstatix", "s2", "sass", "sf", "sp", "stringi", "stringr", "sys", "testthat", "tibble", "tidyr", "tidyverse", "timechange", "tinytex", "tzdb", "units", "utf8", "vctrs", "viridisLite", "vroom", "waldo", "wk", "xfun", "xml2", "yaml"))
install.packages(c("blob", "bookdown", "broom", "bslib", "cachem", "car", "classInt", "cli", "colorspace", "curl", "data.table", "dbplyr", "digest", "dplyr", "DRDID", "dtplyr", "e1071", "evaluate", "fansi", "fastmap", "forcats", "fs", "gargle", "ggplot2", "ggpubr", "ggrepel", "ggsci", "googledrive", "googlesheets4", "gtable", "haven", "highr", "hms", "htmltools", "httr", "isoband", "jpeg", "jsonlite", "knitr", "lme4", "lubridate", "markdown", "modelr", "openssl", "pbapply", "pbkrtest", "pillar", "png", "processx", "ps", "purrr", "quantreg", "Rcpp", "RcppArmadillo", "readr", "readxl", "rgeos", "rlang", "rmarkdown", "rnaturalearth", "rstatix", "s2", "sass", "sf", "sp", "stringi", "stringr", "sys", "testthat", "tibble", "tidyr", "tidyverse", "timechange", "tinytex", "tzdb", "units", "utf8", "vctrs", "viridisLite", "vroom", "waldo", "wk", "xfun", "xml2", "yaml"))
devtools::install_github("synth-inference/synthdid")
install.packages('htmltools')
install.packages("htmltools")
devtools::install_github("synth-inference/synthdid")
library(htmltools)
remove.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
devtools::install_github("synth-inference/synthdid")
library(rlang)
remove.packages("rlang")
install.packages("rlang")
devtools::install_github("synth-inference/synthdid")
library(synthdid)
data('california_prop99')
force(california_prop99)
View(california_prop99)
View(california_prop99)
setup = panel.matrices(california_prop99)
View(setup)
View(california_prop99)
View(california_prop99)
tau.hat = synthdid_estimate(setup$Y, setup$N0, setup$T0)
se = sqrt(vcov(tau.hat, method='placebo'))
sprintf('point estimate: %1.2f', tau.hat)
sprintf('95%% CI (%1.2f, %1.2f)', tau.hat - 1.96 * se, tau.hat + 1.96 * se)
plot(tau.hat)
library(haven)
pcntpreterm <- read_dta("C:/Users/revat/Downloads/pcntpreterm.dta")
View(pcntpreterm)
setup = panel.matrices(pcntpreterm)
setup = panel.matrices(as.data.frame(as_tibble(pcntpreterm)))
install.packages("tibble")
install.packages("tibble")
setup = panel.matrices(as.data.frame(as_tibble(pcntpreterm)))
install.packages("tidyverse")
install.packages("tidyverse")
setup = panel.matrices(as.data.frame(as_tibble(pcntpreterm)))
library(tidyverse)
setup = panel.matrices(as.data.frame(as_tibble(pcntpreterm)))
tau.hat = synthdid_estimate(setup$Y, setup$N0, setup$T0)
se = sqrt(vcov(tau.hat, method='placebo'))
sprintf('point estimate: %1.2f', tau.hat)
sprintf('95%% CI (%1.2f, %1.2f)', tau.hat - 1.96 * se, tau.hat + 1.96 * se)
plot(tau.hat)
library(haven)
pcntlbw <- read_dta("C:/Users/revat/Downloads/pcntlbw.dta")
View(pcntlbw)
sprintf('point estimate: %1.2f', tau.hat)
sprintf('95%% CI (%1.2f, %1.2f)', tau.hat - 1.96 * se, tau.hat + 1.96 * se)
plot(tau.hat)
setup = panel.matrices(as.data.frame(as_tibble(pcntlbw)))
library(haven)
pcntlbw <- read_dta("C:/Users/revat/Downloads/pcntlbw.dta")
View(pcntlbw)
setup = panel.matrices(as.data.frame(as_tibble(pcntlbw)))
tau.hat = synthdid_estimate(setup$Y, setup$N0, setup$T0)
se = sqrt(vcov(tau.hat, method='placebo'))
sprintf('point estimate: %1.2f', tau.hat)
sprintf('95%% CI (%1.2f, %1.2f)', tau.hat - 1.96 * se, tau.hat + 1.96 * se)
plot(tau.hat)
pcntpreterm <- read_dta("C:/Users/revat/Downloads/pcntpreterm")
pcntpreterm <- read_dta("C:/Users/revat/Downloads/pcntpreterm")
library(haven)
pcntpreterm <- read_dta("C:/Users/revat/Downloads/pcntpreterm.dta")
View(pcntpreterm)
setup = panel.matrices(as.data.frame(as_tibble(pcntlbw)))
tau.hat = synthdid_estimate(setup$Y, setup$N0, setup$T0)
se = sqrt(vcov(tau.hat, method='placebo'))
sprintf('point estimate: %1.2f', tau.hat)
sprintf('95%% CI (%1.2f, %1.2f)', tau.hat - 1.96 * se, tau.hat + 1.96 * se)
plot(tau.hat)
library(haven)
pcntlbw <- read_dta("C:/Users/revat/Downloads/pcntlbw.dta")
View(pcntlbw)
setup = panel.matrices(as.data.frame(as_tibble(pcntlbw)))
tau.hat = synthdid_estimate(setup$Y, setup$N0, setup$T0)
se = sqrt(vcov(tau.hat, method='placebo'))
sprintf('point estimate: %1.2f', tau.hat)
sprintf('95%% CI (%1.2f, %1.2f)', tau.hat - 1.96 * se, tau.hat + 1.96 * se)
plot(tau.hat)
install.packages("grf")
library(grf)
Y <- pcntlbw$PacksPerCapita
W <- pcntlbw$treated
school <- pcntlbw$State
cf <- causal_forest(X, Y, W, W.hat = 0.5, clusters = school)
X <- pcntlbw$Year
cf <- causal_forest(X, Y, W, W.hat = 0.5, clusters = school)
setup = panel.matrices(as.data.frame(as_tibble(pcntlbw)))
Y <- setup $PacksPerCapita
Y <- setup$PacksPerCapita
W <- setup$treated
school <- setup$State
cf <- causal_forest( Y, W, W.hat = 0.5, clusters = school)
cf <- causal_forest( Y, W, W.hat = 0.5, clusters = school)
data <- read.csv("C:\\Users\revat\\Downloads\\pcntlbw.csv")
data <- read.csv("C:/Users/revat/Downloads/pcntlbw.csv")
Y <- data$PacksPerCapita
W <- data$treated
school <- data$State
cf <- causal_forest( Y, W, W.hat = 0.5, clusters = school)
data <- read.csv("data/bruhn2016.csv")
X <- data$Year
cf <- causal_forest(X, Y, W, W.hat = 0.5, clusters = school)
data <- read.csv("C:/Users/revat/Downloads/pcntlbw.csv")
Y <- data$PacksPerCapita
W <- data$treated
school <- data$State
X <- data$Year
cf <- causal_forest( Y, W, W.hat = 0.5, clusters = school)
data <- read.csv("C:/Users/revat/Downloads/bruhn2016.csv")
Y <- data$outcome
W <- data$treatment
school <- data$school
X <- data[-(1:3)]
View(data)
data <- read.csv("C:/Users/revat/Downloads/pcntlbw.csv")
View(data)
Y <- data$PacksPerCapita
W <- data$treated
school <- data$stoccfip
X <- data[(6:7)]
cf <- causal_forest(X, Y, W, W.hat = 0.5, clusters = school)
View(cf)
ate <- average_treatment_effect(cf)
ate
varimp <- variable_importance(cf)
varimp
ranked.vars <- order(varimp, decreasing = TRUE)
ranked.vars
best_linear_projection(cf, X[ranked.vars[1:2]])
---
output:
pdf_document:
latex_engine: pdflatex
